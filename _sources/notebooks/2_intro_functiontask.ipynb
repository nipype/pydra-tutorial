{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ff23d5",
   "metadata": {},
   "source": [
    "# 2. FunctionTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c8fead",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f974647",
   "metadata": {},
   "source": [
    "A `FunctionTask` is a `Task` that can be created from every *python* function by using *pydra* decorator: `pydra.mark.task`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b3f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydra\n",
    "\n",
    "@pydra.mark.task\n",
    "def add_var(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643a69ec",
   "metadata": {},
   "source": [
    "Once we decorate the function, we can create a pydra `Task` and specify the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcca005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = add_var(a=4, b=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225944b",
   "metadata": {},
   "source": [
    "We can check the type of `task1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4297ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pydra.engine.task.FunctionTask"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(task1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b5628",
   "metadata": {},
   "source": [
    "and we can check if the task has correct values of `a` and `b`, they should be saved in the task `inputs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f818eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 4\n",
      "b = 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"a = {task1.inputs.a}\")\n",
    "print(f\"b = {task1.inputs.b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5cc50",
   "metadata": {},
   "source": [
    "We can also check content of entire `inputs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a98096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inputs(a=4, b=5, _func=b'\\x80\\x05\\x95\\xc6\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x17cloudpickle.cloudpickle\\x94\\x8c\\x0e_make_function\\x94\\x93\\x94(h\\x00\\x8c\\r_builtin_type\\x94\\x93\\x94\\x8c\\x08CodeType\\x94\\x85\\x94R\\x94(K\\x02K\\x00K\\x00K\\x02K\\x02KCC\\x08|\\x00|\\x01\\x17\\x00S\\x00\\x94N\\x85\\x94)\\x8c\\x01a\\x94\\x8c\\x01b\\x94\\x86\\x94\\x8c!/tmp/ipykernel_1748/3542708107.py\\x94\\x8c\\x07add_var\\x94K\\x03C\\x02\\x00\\x02\\x94))t\\x94R\\x94}\\x94(\\x8c\\x0b__package__\\x94N\\x8c\\x08__name__\\x94\\x8c\\x08__main__\\x94uNNNt\\x94R\\x94\\x8c\\x1ccloudpickle.cloudpickle_fast\\x94\\x8c\\x12_function_setstate\\x94\\x93\\x94h\\x17}\\x94}\\x94(h\\x14h\\x0e\\x8c\\x0c__qualname__\\x94h\\x0e\\x8c\\x0f__annotations__\\x94}\\x94\\x8c\\x0e__kwdefaults__\\x94N\\x8c\\x0c__defaults__\\x94N\\x8c\\n__module__\\x94h\\x15\\x8c\\x07__doc__\\x94N\\x8c\\x0b__closure__\\x94N\\x8c\\x17_cloudpickle_submodules\\x94]\\x94\\x8c\\x0b__globals__\\x94}\\x94u\\x86\\x94\\x86R0.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d352d",
   "metadata": {},
   "source": [
    "As you could see, `task.inputs` contains also information about the function, that is an inseparable part of the `FunctionTask`.\n",
    "\n",
    "Once we have the task with set input, we can run it. Since `Task` is a \"callable object\", we can use the syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99cdf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5c59d8",
   "metadata": {},
   "source": [
    "As you can see, the result was returned right away, but we can also access it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c257d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba226dd4",
   "metadata": {},
   "source": [
    "`Result` contains more than just an output, so if we want to get the task output, we can type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a5ccbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = task1.result()\n",
    "result.output.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6bfdc6",
   "metadata": {},
   "source": [
    "And if we want to see the input that was used in the task, we can set an optional argument `return_inputs` to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8a7231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'add_var.a': 4, 'add_var.b': 5},\n",
       " Result(output=Output(out=9), runtime=None, errored=False))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task1.result(return_inputs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1470cb9b",
   "metadata": {},
   "source": [
    "## Customizing output names\n",
    "Note, that \"out\" is the default name for the task output, but we can always customize it. There are two ways of doing it: using *python* function annotation and using another *pydra* decorator:\n",
    "\n",
    "Let's start from the function annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fc1f220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(sum_a_b=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import typing as ty\n",
    "\n",
    "@pydra.mark.task\n",
    "def add_var_an(a, b) -> {\"sum_a_b\": int}:\n",
    "    return a + b\n",
    "\n",
    "\n",
    "task1a = add_var_an(a=4, b=5)\n",
    "task1a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cb2d4",
   "metadata": {},
   "source": [
    "The annotation might be very useful to specify the output names when the function returns multiple values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eaf8f23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(fractional=0.5, integer=3.0), runtime=None, errored=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydra.mark.task\n",
    "def modf_an(a) -> {\"fractional\": ty.Any, \"integer\": ty.Any}:\n",
    "    import math\n",
    "    return math.modf(a)\n",
    "\n",
    "task2 = modf_an(a=3.5)\n",
    "task2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6911272",
   "metadata": {},
   "source": [
    "The second way of customizing the output requires another decorator - `pydra.mark.annotate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "595d09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(fractional=0.5, integer=3.0), runtime=None, errored=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate({\"return\": {\"fractional\": ty.Any, \"integer\": ty.Any}})\n",
    "def modf(a):\n",
    "    import math\n",
    "    return math.modf(a)\n",
    "\n",
    "task2a = modf(a=3.5)\n",
    "task2a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0b888",
   "metadata": {},
   "source": [
    "**Note, that the order of the pydra decorators is important!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6197bf8c",
   "metadata": {},
   "source": [
    "## Setting the input\n",
    "\n",
    "We don't have to provide the input when we create a task, we can always set it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8691fed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=None, errored=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3 = add_var()\n",
    "task3.inputs.a = 4\n",
    "task3.inputs.b = 5\n",
    "task3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6e8a26",
   "metadata": {},
   "source": [
    "If we don't specify the input, `attr.NOTHING` will be used as the default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e50bd8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3a = add_var()\n",
    "task3a.inputs.a = 4\n",
    "\n",
    "# importing attr library, and checking the type pf `b`\n",
    "import attr\n",
    "task3a.inputs.b == attr.NOTHING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1e4dd",
   "metadata": {},
   "source": [
    "And if we try to run the task, an error will be raised:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c299706",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and '_Nothing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtask3a\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pydra/engine/core.py:452\u001b[0m, in \u001b[0;36mTaskBase.__call__\u001b[0;34m(self, submitter, plugin, plugin_kwargs, rerun, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m         res \u001b[38;5;241m=\u001b[39m sub(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# tasks without state could be run without a submitter\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrerun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrerun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pydra/engine/core.py:489\u001b[0m, in \u001b[0;36mTaskBase._run\u001b[0;34m(self, rerun, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudit\u001b[38;5;241m.\u001b[39mmonitor()\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m     result\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_outputs(output_dir\u001b[38;5;241m=\u001b[39modir)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/hostedtoolcache/Python/3.9.13/x64/lib/python3.9/site-packages/pydra/engine/task.py:187\u001b[0m, in \u001b[0;36mFunctionTask._run_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_func\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m output_names \u001b[38;5;241m=\u001b[39m [el[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_spec\u001b[38;5;241m.\u001b[39mfields]\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36madd_var\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;129m@pydra\u001b[39m\u001b[38;5;241m.\u001b[39mmark\u001b[38;5;241m.\u001b[39mtask\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_var\u001b[39m(a, b):\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and '_Nothing'"
     ]
    }
   ],
   "source": [
    "task3a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e99e3",
   "metadata": {},
   "source": [
    "## Output directory and caching the results\n",
    "\n",
    "After running the task, we can check where the output directory with the results was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06281506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tmp/tmpy4i2c4dm/FunctionTask_563ca12d08c1dad2379dcb7dd3daa067545d9c8fadb090065f349aca3ac7a2cc')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659f94c",
   "metadata": {},
   "source": [
    "Within the directory you can find the file with the results: `_result.pklz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f51e608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_task.pklz', '_result.pklz']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(task3.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616798f",
   "metadata": {},
   "source": [
    "But we can also provide the path where we want to store the results. If a path is provided for the cache directory, then pydra will use the cached results of a node instead of recomputing the result. Let's create a temporary directory and a specific subdirectory \"task4\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d3ca28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpy46vwfkq/task4\n"
     ]
    }
   ],
   "source": [
    "from tempfile import mkdtemp\n",
    "from pathlib import Path\n",
    "cache_dir_tmp = Path(mkdtemp()) / \"task4\"\n",
    "print(cache_dir_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8381e19",
   "metadata": {},
   "source": [
    "Now we can pass this path to the argument of `FunctionTask` - `cache_dir`. To observe the execution time, we specify a function that is sleeping for 5s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e58a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "def add_var_wait(a, b):\n",
    "    import time\n",
    "    time.sleep(5)\n",
    "    return a + b\n",
    "\n",
    "task4 = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba636446",
   "metadata": {},
   "source": [
    "If you're running the cell first time, it should take around 5s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0b37397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=10), runtime=None, errored=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4()\n",
    "task4.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7a30e",
   "metadata": {},
   "source": [
    "We can check `output_dir` of our task, it should contain the path of `cache_dir_tmp` and the last part contains the name of the task class `FunctionTask` and the task checksum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2122a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tmp/tmpy46vwfkq/task4/FunctionTask_9e28c11b45c56e98e53bb6dfdcf2dd2ab7e9efbf76f6852907631ca61e755150')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aaf9db",
   "metadata": {},
   "source": [
    "Let's see what happens when we defined identical task again with the same `cache_dir`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4df3da2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=10), runtime=None, errored=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4a = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp)\n",
    "task4a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df82504",
   "metadata": {},
   "source": [
    "This time the result should be ready right away! *pydra* uses available results and do not recompute the task.\n",
    "\n",
    "*pydra* not only checks for the results in `cache_dir`, but you can provide a list of other locations that should be checked. Let's create another directory that will be used as `cache_dir` and previous working directory will be used in `cache_locations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0311aad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=10), runtime=None, errored=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir_tmp_new = Path(mkdtemp()) / \"task4b\"\n",
    "\n",
    "task4b = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp_new, cache_locations=[cache_dir_tmp])\n",
    "task4b()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d1f5e",
   "metadata": {},
   "source": [
    "This time the results should be also returned quickly! And we can check that `task4b.output_dir` was not created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41a87e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4b.output_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3914cf",
   "metadata": {},
   "source": [
    "If you want to rerun the task regardless having already the results, you can set `rerun` to `True`. The task will take several seconds and new `output_dir` will be created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14fea8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache_dir_tmp_new = Path(mkdtemp()) / \"task4c\"\n",
    "\n",
    "task4c = add_var_wait(a=4, b=6, cache_dir=cache_dir_tmp_new, cache_locations=[cache_dir_tmp])\n",
    "task4c(rerun=True)\n",
    "\n",
    "task4c.output_dir.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0af1d",
   "metadata": {},
   "source": [
    "If we update the input of the task, and run again, the new directory will be created and task will be recomputed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01013f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(output=Output(out=7), runtime=None, errored=False)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "task4b.inputs.a = 1\n",
    "print(task4b())\n",
    "print(task4b.output_dir.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00091b24",
   "metadata": {},
   "source": [
    "and when we check the `output_dir`, we can see that it's different than last time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87fec1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tmp/tmput1bzz22/task4b/FunctionTask_215e6ee73d532d584d34c1790833e6a8018501e673a25df525f041c1303f1b54')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task4b.output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d6ad78",
   "metadata": {},
   "source": [
    "This is because, the checksum changes when we change either input or function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ffb84",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise 1\n",
    "Create a task that take a list of numbers as an input and returns two fields: `mean` with the mean value and `std` with the standard deviation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff4f66bb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(mean=2, std=0.0), runtime=None, errored=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate({\"return\": {\"mean\": ty.Any, \"std\": ty.Any}})\n",
    "def mean_dev(my_list):\n",
    "    import statistics as st\n",
    "    return st.mean(my_list), st.stdev(my_list)\n",
    "\n",
    "my_task = mean_dev(my_list=[2, 2, 2])\n",
    "my_task()\n",
    "my_task.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a12e2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your solution here (you can use statistics module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f8177",
   "metadata": {},
   "source": [
    "## Using Audit\n",
    "\n",
    "*pydra* can record various run time information, including the workflow provenance, by setting `audit_flags` and the type of messengers. \n",
    "\n",
    "`AuditFlag.RESOURCE` allows you to monitor resource usage for the `Task`, while `AuditFlag.PROV` tracks the provenance of the `Task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3c7a8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=Runtime(rss_peak_gb=0.0888824462890625, vms_peak_gb=0.849815369140625, cpu_peak_percent=162.8), errored=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydra.utils.messenger import AuditFlag, PrintMessenger\n",
    "\n",
    "task5 = add_var(a=4, b=5, audit_flags=AuditFlag.RESOURCE)\n",
    "task5()\n",
    "task5.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ed9300",
   "metadata": {},
   "source": [
    "One can turn on both audit flags using `AuditFlag.ALL`, and print the messages on the terminal using the `PrintMessenger`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "456d1462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 09a38e46c3164c78a38f8ad164d9eb15\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:9beafff879c24f07a27973594fafa417\",\n",
      "  \"@type\": \"task\",\n",
      "  \"startedAtTime\": \"2022-07-06T17:02:20.324913\"\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: fc0527d848b7439c911cb111c762be89\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:fa2e1cce2bea4c498a5354f004737488\",\n",
      "  \"@type\": \"monitor\",\n",
      "  \"startedAtTime\": \"2022-07-06T17:02:20.533807\",\n",
      "  \"wasStartedBy\": \"uid:9beafff879c24f07a27973594fafa417\"\n",
      "}\n",
      "id: 3e93cdc79c4043d29e67664896b98411\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:fa2e1cce2bea4c498a5354f004737488\",\n",
      "  \"endedAtTime\": \"2022-07-06T17:02:20.565085\",\n",
      "  \"wasEndedBy\": \"uid:9beafff879c24f07a27973594fafa417\"\n",
      "}\n",
      "id: 163c797b0b9d4530b1c0f7b8d694d836\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"rss_peak_gb\": 0.0888824462890625,\n",
      "  \"vms_peak_gb\": 0.849815369140625,\n",
      "  \"cpu_peak_percent\": 109.0,\n",
      "  \"@id\": \"uid:95fe7b52c790472dbd393e154ae42b1f\",\n",
      "  \"@type\": \"runtime\",\n",
      "  \"prov:wasGeneratedBy\": \"uid:9beafff879c24f07a27973594fafa417\"\n",
      "}\n",
      "id: 381f3b172b924a6aabeee45533fa389d\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@type\": \"prov:Generation\",\n",
      "  \"entity_generated\": \"uid:95fe7b52c790472dbd393e154ae42b1f\",\n",
      "  \"hadActivity\": \"uid:fa2e1cce2bea4c498a5354f004737488\"\n",
      "}\n",
      "id: 347d44e0efca491eb5a76fc8bf987b7f\n",
      "{\n",
      "  \"@context\": \"https://raw.githubusercontent.com/nipype/pydra/master/pydra/schema/context.jsonld\",\n",
      "  \"@id\": \"uid:9beafff879c24f07a27973594fafa417\",\n",
      "  \"endedAtTime\": \"2022-07-06T17:02:20.565331\",\n",
      "  \"errored\": false\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(output=Output(out=9), runtime=Runtime(rss_peak_gb=0.0888824462890625, vms_peak_gb=0.849815369140625, cpu_peak_percent=109.0), errored=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task5 = add_var(a=4, b=5, audit_flags=AuditFlag.ALL, messengers=PrintMessenger())\n",
    "task5()\n",
    "task5.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8c68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.13.8"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "source_map": [
   13,
   18,
   29,
   33,
   39,
   43,
   45,
   49,
   51,
   55,
   58,
   62,
   64,
   70,
   72,
   76,
   78,
   82,
   85,
   89,
   91,
   98,
   108,
   112,
   120,
   124,
   133,
   137,
   143,
   148,
   152,
   159,
   163,
   167,
   173,
   175,
   179,
   182,
   186,
   191,
   195,
   203,
   207,
   210,
   214,
   216,
   220,
   223,
   229,
   234,
   238,
   240,
   244,
   251,
   255,
   259,
   263,
   265,
   269,
   274,
   288,
   290,
   298,
   304,
   308,
   314
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}