{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165d8350",
   "metadata": {},
   "source": [
    "# Two-Level GLM (from Nilearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71991b1",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrate how to write pydra tasks for the first level (subject-level) GLM and the second level (group-level) GLM in Nilearn. We use the data from [Balloon Analog Risk-taking Task](https://openneuro.org/datasets/ds000001/versions/1.0.0). \n",
    "Basic information about this dataset:\n",
    "- 16 subjects\n",
    "- 3 runs\n",
    "- functional scan TR: 2.3 \n",
    "- num of functional scan: 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de885bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b863bd3",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Import packages that will be used globally and set up output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ec9369",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'getargspec' from 'inspect' (/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/inspect.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mty\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatalad\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdl\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/datalad/__init__.py:23\u001b[0m\n\u001b[1;32m     17\u001b[0m     random\u001b[38;5;241m.\u001b[39mseed(_seed)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Other imports are interspersed with lgr.debug to ease troubleshooting startup\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# delays etc.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# If there is a bundled git, make sure GitPython uses it too:\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatalad\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GitRunner\n\u001b[1;32m     24\u001b[0m GitRunner\u001b[38;5;241m.\u001b[39m_check_git_path()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GitRunner\u001b[38;5;241m.\u001b[39m_GIT_PATH:\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/datalad/cmd.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CommandError\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msupport\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NullProtocol, DryRunProtocol, \\\n\u001b[1;32m     34\u001b[0m     ExecutionTimeProtocol, ExecutionTimeExternalsProtocol\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m on_windows, get_tempfile_kwargs, assure_unicode\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdochelpers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m borrowdoc\n\u001b[1;32m     38\u001b[0m lgr \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatalad.cmd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/datalad/utils.py:29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wraps\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sleep\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getargspec\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sep \u001b[38;5;28;01mas\u001b[39;00m dirsep\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m commonprefix\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'getargspec' from 'inspect' (/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/inspect.py)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import os, glob\n",
    "import datetime\n",
    "import random\n",
    "import pydra\n",
    "from pydra import Workflow\n",
    "from pydra.engine.specs import File, MultiInputFile, MultiOutputFile\n",
    "import typing as ty\n",
    "from pathlib import Path\n",
    "import datalad.api as dl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from scipy.stats import norm\n",
    "from nilearn.interfaces.fmriprep import load_confounds_strategy\n",
    "from nilearn.image import load_img, get_data, math_img, threshold_img\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix, FirstLevelModel\n",
    "from nilearn.glm.second_level import SecondLevelModel, non_parametric_inference\n",
    "from nilearn.glm.contrasts import compute_fixed_effects\n",
    "from nilearn.plotting import plot_stat_map, plot_glass_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4aedc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current directory\n",
    "pydra_tutorial_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# set up output directory\n",
    "workflow_dir = Path(pydra_tutorial_dir) / 'outputs'\n",
    "workflow_out_dir = workflow_dir / '9_glm' /'results'\n",
    "\n",
    "# create folders if not exit\n",
    "os.makedirs(workflow_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10d306",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "\n",
    "[DataLad](http://handbook.datalad.org/en/latest/index.htmlhttp://handbook.datalad.org/en/latest/index.html) is often used in those cases to download data. Here we use its [Python API](http://docs.datalad.org/en/latest/modref.htmlhttp://docs.datalad.org/en/latest/modref.html).\n",
    "\n",
    "We need the following data: \n",
    "\n",
    "1. event information (raw data)\n",
    "2. preprocessed image data (fmriprep)\n",
    "3. masks (fmriprep)\n",
    "4. confounds (fmriprep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5934c1f",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m fmriprep_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/OpenNeuroDerivatives/ds000001-fmriprep.git\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m rawdata_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/OpenNeuroDatasets/ds000001.git\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdl\u001b[49m\u001b[38;5;241m.\u001b[39minstall(source\u001b[38;5;241m=\u001b[39mrawdata_url, path\u001b[38;5;241m=\u001b[39mrawdata_path)\n\u001b[1;32m      9\u001b[0m dl\u001b[38;5;241m.\u001b[39minstall(source\u001b[38;5;241m=\u001b[39mfmriprep_url, path\u001b[38;5;241m=\u001b[39mfmriprep_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dl' is not defined"
     ]
    }
   ],
   "source": [
    "fmriprep_path = workflow_dir / '7_glm'/ 'data'\n",
    "rawdata_path = workflow_dir / '7_glm' / 'raw_data'\n",
    "os.makedirs(fmriprep_path, exist_ok=True)\n",
    "os.makedirs(rawdata_path, exist_ok=True)\n",
    "# Install datasets to specific datapaths\n",
    "fmriprep_url = 'https://github.com/OpenNeuroDerivatives/ds000001-fmriprep.git'\n",
    "rawdata_url = 'https://github.com/OpenNeuroDatasets/ds000001.git'\n",
    "dl.install(source=rawdata_url, path=rawdata_path)\n",
    "dl.install(source=fmriprep_url, path=fmriprep_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eeba266",
   "metadata": {},
   "source": [
    "### Get data for each subject\n",
    "\n",
    "By `datalad.api.install`, datalad downloads all symlinks without storing the actual data locally. We can then use `datalad.api.get` to get the data we need for our analysis. \n",
    "We need to get four types of data from two folders:\n",
    "\n",
    "1. event_info: `*events.tsv` from `rawdata_path`\n",
    "2. bold: `*space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz` from `fmriprep_path`\n",
    "3. mask: `*space-MNI152NLin2009cAsym_res-2_desc-brain_mask.nii.gz` from `fmriprep_path`\n",
    "4. confounds: `*desc-confounds_timeseries.tsv` from `fmriprep_path` (this is implicitly needed by `load_confounds_strategy`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70fb9425",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'return': {'subj_id': int, 'subj_events': list, 'subj_imgs':list, 'subj_masks':list},\n",
    "    }\n",
    ")\n",
    "def get_subjdata(subj_id):\n",
    "    print(f\"\\nDownload data for subject-{subj_id}\")\n",
    "    # get events.tsv \n",
    "    subj_events = glob.glob(os.path.join(rawdata_path, 'sub-%02d' % subj_id, 'func', '*events.tsv'))\n",
    "    subj_events.sort()\n",
    "    for i in subj_events:\n",
    "        dl.get(i, dataset=rawdata_path)\n",
    "    # get bold\n",
    "    subj_imgs = glob.glob(os.path.join(fmriprep_path, 'sub-%02d' % subj_id, 'func', '*space-MNI152NLin2009cAsym_res-2_desc-preproc_bold.nii.gz'))\n",
    "    subj_imgs.sort()\n",
    "    for i in subj_imgs:\n",
    "        dl.get(i, dataset=fmriprep_path)\n",
    "    # get mask\n",
    "    subj_masks = glob.glob(os.path.join(fmriprep_path, 'sub-%02d' % subj_id, 'func', '*space-MNI152NLin2009cAsym_res-2_desc-brain_mask.nii.gz'))\n",
    "    subj_masks.sort()\n",
    "    for i in subj_masks:\n",
    "        dl.get(i, dataset=fmriprep_path)\n",
    "    # get confounds list\n",
    "    subj_confounds = glob.glob(os.path.join(fmriprep_path, 'sub-%02d' % subj_id, 'func', '*desc-confounds_timeseries.tsv'))\n",
    "    subj_confounds.sort()\n",
    "    for i in subj_confounds:\n",
    "        dl.get(i, dataset=fmriprep_path)\n",
    "    return subj_id, subj_events, subj_imgs, subj_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a2d08",
   "metadata": {},
   "source": [
    "## First-Level GLM\n",
    "\n",
    "The first level GLM has two parts:\n",
    "- conduct GLM for each run on every subject\n",
    "- average across runs for each subject with a fixed-effect model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56634874",
   "metadata": {},
   "source": [
    "### Get the first-level design matrix\n",
    "\n",
    "The design matrix is a _M(row)_ x _N(columns)_ matrix. _M_ corresponds to the number of _tr_, while _N_ corresponds to event conditions + confounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "797b5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'tr': float,\n",
    "        'n_scans': int,\n",
    "        'hrf_model': str,\n",
    "        'subj_id': int,\n",
    "        'run_id': int,\n",
    "        'subj_imgs': list,\n",
    "        'subj_events':list,\n",
    "        'return': {'dm_path': str, 'run_id': int},\n",
    "    }\n",
    ")\n",
    "def get_firstlevel_dm(tr, n_scans, hrf_model, subj_id, run_id, subj_imgs, subj_events):\n",
    "    print(f\"\\nGet subject-{subj_id}, run-{run_id} firstlevel GLM design matrix...\\n\")\n",
    "    # read event file\n",
    "    run_img = subj_imgs[run_id-1]\n",
    "    run_event = subj_events[run_id-1]\n",
    "    event = pd.read_csv(run_event, sep='\\t').fillna(0)\n",
    "    event = event[['onset', 'duration', 'trial_type']]\n",
    "    # get list of confounds directly from fmriprepped bold\n",
    "    confounds = load_confounds_strategy(run_img, denoise_strategy='simple')[0]\n",
    "    frame_times = np.arange(n_scans) * tr\n",
    "    design_matrix = make_first_level_design_matrix(frame_times, event, \n",
    "                                                   hrf_model=hrf_model,\n",
    "                                                   add_regs=confounds)          \n",
    "\n",
    "    # make sure all design matrices have the same length of column\n",
    "    # if you have a block design, this is not needed.\n",
    "    # 39 = 4(events) + 34(confounds) + 13(drift) + 1(constant)\n",
    "    assert design_matrix.shape[1] == 52, \"This design matrix has the wrong column number\"\n",
    "    # sort the column order alphabetical for contrasts\n",
    "    design_matrix = design_matrix.reindex(sorted(design_matrix.columns), axis=1)\n",
    "    dm_path = os.path.join(workflow_out_dir, 'sub-%s_run-%s_designmatrix.csv' % (subj_id, run_id))\n",
    "    design_matrix.to_csv(dm_path, index=None)\n",
    "    return dm_path, run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2a97ad",
   "metadata": {},
   "source": [
    "### Set up the first level contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33c83801",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'run_id': int,\n",
    "        'dm_path': str,\n",
    "        'return': {'contrasts': dict},\n",
    "    }\n",
    ")\n",
    "def set_contrast(subj_id, run_id, dm_path):\n",
    "    print(f\"\\nSet firstlevel contrast for subject-{subj_id}, run-{run_id} ...\\n\") \n",
    "    design_matrix = pd.read_csv(dm_path)\n",
    "    contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "    basic_contrasts = dict([(column, contrast_matrix[i])\n",
    "                      for i, column in enumerate(design_matrix.columns)])\n",
    "    contrasts = {\n",
    "        'pumps-control': basic_contrasts['pumps_demean'] - basic_contrasts['control_pumps_demean'],\n",
    "        'control-pumps': -basic_contrasts['control_pumps_demean'] + basic_contrasts['pumps_demean'],\n",
    "        'pumps-baseline': basic_contrasts['pumps_demean'],\n",
    "        'cash-baseline': basic_contrasts['cash_demean'],\n",
    "        'explode-baseline': basic_contrasts['explode_demean']\n",
    "        }\n",
    "    return contrasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736335e1",
   "metadata": {},
   "source": [
    "### Fit the first level GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66ca2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {\n",
    "        'subj_id': int,\n",
    "        'run_id': int,\n",
    "        'subj_imgs': list,\n",
    "        'subj_masks': list,\n",
    "        'smoothing_fwhm': float,\n",
    "        'dm_path': str,\n",
    "        'contrasts':dict,\n",
    "        'return': {'effect_size_path_dict': dict, 'effect_variance_path_dict': dict},\n",
    "    }\n",
    ")\n",
    "def firstlevel_estimation(subj_id, run_id, subj_imgs, subj_masks, smoothing_fwhm, dm_path, contrasts):\n",
    "    print(f\"\\nStart firstlevel estimation for subject-{subj_id}, run-{run_id} ...\\n\")\n",
    "    \n",
    "    # subsample img to reduce memory\n",
    "    run_img = subj_imgs[run_id-1]\n",
    "    img = load_img(run_img)\n",
    "    img_data = get_data(run_img)[::2,::2,::2]\n",
    "    new_img = nib.Nifti1Image(img_data, img.affine)\n",
    "    run_mask = subj_masks[run_id-1]\n",
    "    print('Fit the firstlevel model...')\n",
    "    first_level_model = FirstLevelModel(mask_img=run_mask, smoothing_fwhm=smoothing_fwhm)\n",
    "    dm= pd.read_csv(dm_path)\n",
    "    first_level_model = first_level_model.fit(new_img, design_matrices=dm)\n",
    "    print('Computing contrasts...')\n",
    "    effect_size_path_dict = dict.fromkeys(contrasts.keys())\n",
    "    effect_variance_path_dict = dict.fromkeys(contrasts.keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts.items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(contrasts), contrast_id))\n",
    "        # Estimate the contasts. Note that the model implicitly computes a fixed\n",
    "        # effect across the two sessions\n",
    "        res = first_level_model.compute_contrast(contrast_val, output_type='all')\n",
    "        # write the resulting stat images to file\n",
    "        effect_size_path = os.path.join(workflow_out_dir, 'sub-%s_run-%s_contrast-%s_effect_size.nii.gz' % (subj_id, run_id, contrast_id))\n",
    "        effect_variance_path = os.path.join(workflow_out_dir, 'sub-%s_run-%s_contrast-%s_effect_varaince.nii.gz' % (subj_id, run_id, contrast_id))\n",
    "        effect_size_path_dict[contrast_id] = effect_size_path\n",
    "        effect_variance_path_dict[contrast_id] = effect_variance_path\n",
    "        res['effect_size'].to_filename(effect_size_path)\n",
    "        res['effect_variance'].to_filename(effect_variance_path)\n",
    "        \n",
    "    return effect_size_path_dict, effect_variance_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e2ccf",
   "metadata": {},
   "source": [
    "### Create the first level GLM workflow\n",
    "\n",
    "This workflow include GLM for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the first-level GLM workflow\n",
    "wf_firstlevel = Workflow(\n",
    "    name='wf_firstlevel',\n",
    "    input_spec=[\n",
    "        'subj_id',\n",
    "        'run_id',\n",
    "        'subj_imgs',\n",
    "        'subj_events',\n",
    "        'subj_masks',\n",
    "        'tr',\n",
    "        'n_scans',\n",
    "        'hrf_model',\n",
    "        'smoothing_fwhm'\n",
    "    ],\n",
    ")\n",
    "\n",
    "wf_firstlevel.split('run_id', run_id = wf_firstlevel.lzin.run_id)\n",
    "# add task - get_firstlevel_dm\n",
    "wf_firstlevel.add(\n",
    "    get_firstlevel_dm(\n",
    "        name = \"get_firstlevel_dm\",\n",
    "        tr = wf_firstlevel.lzin.tr, \n",
    "        n_scans = wf_firstlevel.lzin.n_scans, \n",
    "        hrf_model = wf_firstlevel.lzin.hrf_model, \n",
    "        subj_id = wf_firstlevel.lzin.subj_id, \n",
    "        run_id = wf_firstlevel.lzin.run_id, \n",
    "        subj_imgs = wf_firstlevel.lzin.subj_imgs, \n",
    "        subj_events = wf_firstlevel.lzin.subj_events,\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - set_contrast\n",
    "wf_firstlevel.add(\n",
    "    set_contrast(\n",
    "        name = \"set_contrast\",\n",
    "        subj_id = wf_firstlevel.lzin.subj_id,\n",
    "        run_id = wf_firstlevel.get_firstlevel_dm.lzout.run_id,\n",
    "        dm_path = wf_firstlevel.get_firstlevel_dm.lzout.dm_path\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - firstlevel_estimation\n",
    "wf_firstlevel.add(\n",
    "    firstlevel_estimation(\n",
    "        name = \"firstlevel_estimation\",\n",
    "        subj_id = wf_firstlevel.lzin.subj_id, \n",
    "        run_id = wf_firstlevel.get_firstlevel_dm.lzout.run_id, \n",
    "        subj_imgs = wf_firstlevel.lzin.subj_imgs, \n",
    "        subj_masks = wf_firstlevel.lzin.subj_masks,\n",
    "        smoothing_fwhm = wf_firstlevel.lzin.smoothing_fwhm, \n",
    "        dm_path = wf_firstlevel.get_firstlevel_dm.lzout.dm_path, \n",
    "        contrasts = wf_firstlevel.set_contrast.lzout.contrasts\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "wf_firstlevel.combine('run_id')\n",
    "# specify output\n",
    "wf_firstlevel.set_output(\n",
    "    [\n",
    "        ('first_level_contrast', wf_firstlevel.set_contrast.lzout.contrasts),\n",
    "        ('first_level_effect_size_list', wf_firstlevel.firstlevel_estimation.lzout.effect_size_path_dict),\n",
    "        ('first_level_effect_variance_list', wf_firstlevel.firstlevel_estimation.lzout.effect_variance_path_dict),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e54d5d",
   "metadata": {},
   "source": [
    "### Compute fixed effects\n",
    "\n",
    "Before we move to the second(group) level, we need to average results from all three runs from a fixed effect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c91f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'subj_id': int, \n",
    "     'subj_masks': list,\n",
    "     'contrasts': list,\n",
    "     'effect_size_path_dict_list': list,\n",
    "     'effect_variance_path_dict_list': list,\n",
    "     'return': {'fixed_fx_contrast_path_dict': dict, 'fixed_fx_variance_path_dict': dict, 'fixed_fx_ttest_path_dict': dict},\n",
    "    }\n",
    ")\n",
    "def get_fixed_effcts(subj_id, subj_masks, contrasts, effect_size_path_dict_list, effect_variance_path_dict_list):\n",
    "    print(f\"contrast:{contrast}\")\n",
    "    print(f'Compute fixed effects for subject-{subj_id}...')\n",
    "    # average mask across three runs\n",
    "    mean_mask = math_img('np.mean(img, axis=-1)', img=subj_masks)\n",
    "    # binarize the mean mask\n",
    "    mask = math_img('img > 0', img=mean_mask)\n",
    "    fixed_fx_contrast_path_dict =dict.fromkeys(contrasts[0].keys())\n",
    "    fixed_fx_variance_path_dict = dict.fromkeys(contrasts[0].keys())\n",
    "    fixed_fx_ttest_path_dict = dict.fromkeys(contrasts[0].keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrasts[0].items()):\n",
    "        print(' Contrast % 2i out of %i: %s' % (index + 1, len(contrasts[0]), contrast_id))\n",
    "        contrast_imgs = [nib.load(img_dict[contrast_id]) for img_dict in effect_size_path_dict_list]\n",
    "        variance_imgs = [nib.load(img_dict[contrast_id]) for img_dict in effect_variance_path_dict_list]\n",
    "        fixed_fx_contrast, fixed_fx_variance, fixed_fx_ttest = compute_fixed_effects(contrast_imgs, variance_imgs, mask)\n",
    "        \n",
    "        effect_size_path = os.path.join(workflow_out_dir, 'sub-%s_contrast-%s_fx_effect_size.nii.gz' % (subj_id, contrast_id))\n",
    "        variance_path = os.path.join(workflow_out_dir, 'sub-%s_contrast-%s_fx_effect_varaince.nii.gz' % (subj_id, contrast_id))\n",
    "        ttest_path = os.path.join(workflow_out_dir, 'sub-%s_contrast-%s_ttest_map.nii.gz' % (subj_id, contrast_id))\n",
    "        fixed_fx_contrast_path_dict[contrast_id] = effect_size_path\n",
    "        fixed_fx_variance_path_dict[contrast_id] = variance_path\n",
    "        fixed_fx_ttest_path_dict[contrast_id]  = ttest_path\n",
    "        \n",
    "        fixed_fx_contrast.to_filename(effect_size_path)\n",
    "        fixed_fx_variance.to_filename(variance_path)\n",
    "        fixed_fx_ttest.to_filename(ttest_path)\n",
    "    return fixed_fx_contrast_path_dict, fixed_fx_variance_path_dict, fixed_fx_ttest_path_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c690a",
   "metadata": {},
   "source": [
    "### Create the fixed effect workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "111aae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LazyOutField(name='wf_fixed_effect', field='first_level_contrast', type=typing.List[typing.List[dict]], splits=frozenset(), cast_from=None)\n"
     ]
    }
   ],
   "source": [
    "# initiate the fixed effect GLM workflow\n",
    "wf_fixed_effect = Workflow(\n",
    "    name='wf_fixed_effect',\n",
    "    input_spec=[\n",
    "        'subj_id',\n",
    "        'run_id',\n",
    "        'tr',\n",
    "        'n_scans',\n",
    "        'hrf_model',\n",
    "        'smoothing_fwhm'\n",
    "    ],\n",
    ")\n",
    "\n",
    "wf_fixed_effect.split('subj_id', subj_id = wf_fixed_effect.lzin.subj_id)\n",
    "# add task - get_subj_file\n",
    "wf_fixed_effect.add(\n",
    "    get_subjdata(\n",
    "        name = \"get_subjdata\",\n",
    "        subj_id = wf_fixed_effect.lzin.subj_id, \n",
    "    )\n",
    ")\n",
    "wf_firstlevel.inputs.subj_id = wf_fixed_effect.get_subjdata.lzout.subj_id\n",
    "wf_firstlevel.inputs.run_id = wf_fixed_effect.lzin.run_id\n",
    "wf_firstlevel.inputs.tr = wf_fixed_effect.lzin.tr\n",
    "wf_firstlevel.inputs.n_scans = wf_fixed_effect.lzin.n_scans\n",
    "wf_firstlevel.inputs.hrf_model = wf_fixed_effect.lzin.hrf_model\n",
    "wf_firstlevel.inputs.smoothing_fwhm = wf_fixed_effect.lzin.smoothing_fwhm\n",
    "wf_firstlevel.inputs.subj_imgs = wf_fixed_effect.get_subjdata.lzout.subj_imgs\n",
    "wf_firstlevel.inputs.subj_events = wf_fixed_effect.get_subjdata.lzout.subj_events\n",
    "wf_firstlevel.inputs.subj_masks = wf_fixed_effect.get_subjdata.lzout.subj_masks\n",
    "wf_fixed_effect.add(wf_firstlevel)\n",
    "\n",
    "wf_fixed_effect.add(\n",
    "    get_fixed_effcts(\n",
    "        name = \"get_fixed_effcts\",\n",
    "        subj_id = wf_fixed_effect.get_subjdata.lzout.subj_id, \n",
    "        subj_masks = wf_fixed_effect.get_subjdata.lzout.subj_masks,\n",
    "        contrasts = wf_fixed_effect.wf_firstlevel.lzout.first_level_contrast, \n",
    "        effect_size_path_dict_list = wf_fixed_effect.wf_firstlevel.lzout.first_level_effect_size_list, \n",
    "        effect_variance_path_dict_list = wf_fixed_effect.wf_firstlevel.lzout.first_level_effect_variance_list\n",
    "    )\n",
    ")\n",
    "\n",
    "wf_fixed_effect.combine('subj_id')\n",
    "# specify output\n",
    "wf_fixed_effect.set_output(\n",
    "    [\n",
    "        ('first_level_contrast', wf_fixed_effect.wf_firstlevel.lzout.first_level_contrast),\n",
    "        ('fx_effect_size_list', wf_fixed_effect.get_fixed_effcts.lzout.fixed_fx_contrast_path_dict),\n",
    "        ('fx_effect_variance_list', wf_fixed_effect.get_fixed_effcts.lzout.fixed_fx_variance_path_dict),\n",
    "        ('fx_t_test_list', wf_fixed_effect.get_fixed_effcts.lzout.fixed_fx_ttest_path_dict),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(wf_fixed_effect.lzout.first_level_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ddbe97",
   "metadata": {},
   "source": [
    "## Second-Level GLM\n",
    "\n",
    "The second level GLM, as known as the group level, averages results across subjects, containing the following steps:\n",
    "- construct design matrix\n",
    "- fit the second-level GLM\n",
    "- statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73446206",
   "metadata": {},
   "source": [
    "### Get the second level design matrix\n",
    "\n",
    "This is a one-group design. So we need a design matrix for a one-sample test.\n",
    "\n",
    "The design matrix is a single column of ones, corresponding to the model intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ea45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'n_subj': int, 'return': {'design_matrix': ty.Any}}\n",
    ")\n",
    "def get_secondlevel_dm(n_subj):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(f\"\\nGet secondlevel design matrix ...\\n\")\n",
    "    design_matrix = pd.DataFrame([1] * n_subj,columns=['intercept'])\n",
    "    return design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2e3e4c",
   "metadata": {},
   "source": [
    "### Fit the second level GLM\n",
    "\n",
    "Here, we use the list of FirstLevel z-maps as the input for the SecondLevelModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea44b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'firstlevel_stats_list': list, 'design_matrix': ty.Any, 'firstlevel_contrast':list, \n",
    "     'return': {'secondlevel_mask': ty.Any, 'stat_maps_dict': dict}}\n",
    ")\n",
    "def secondlevel_estimation(firstlevel_stats_list, design_matrix, firstlevel_contrast):   \n",
    "    print(f\"\\nStart secondlevel estimation ...\\n\")\n",
    "    stat_maps_dict = dict.fromkeys(firstlevel_contrast[0][0].keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(firstlevel_contrast[0][0].items()):\n",
    "        print(' Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(firstlevel_contrast[0][0]), contrast_id))\n",
    "        second_level_input = [nib.load(stats_dict[contrast_id]) for stats_dict in firstlevel_stats_list]\n",
    "        second_level_model = SecondLevelModel()\n",
    "        second_level_model = second_level_model.fit(second_level_input, design_matrix=design_matrix)\n",
    "        secondlevel_mask = second_level_model.masker_.mask_img_\n",
    "    \n",
    "        stats = second_level_model.compute_contrast(output_type='all')\n",
    "        # write the resulting stat images to file\n",
    "        z_image_path = os.path.join(workflow_out_dir, 'secondlevel_contrast-%s_z_map.nii.gz' % contrast_id)\n",
    "        stat_maps_dict[contrast_id] = stats\n",
    "        stats['z_score'].to_filename(z_image_path)\n",
    "        plot_path = os.path.join(workflow_out_dir, 'secondlevel_unthresholded_contrast-%s_zmap.jpg' % contrast_id)\n",
    "        plot_glass_brain(stats['z_score'],\n",
    "                         colorbar=True,\n",
    "                         threshold=norm.isf(0.001),\n",
    "                         title='Unthresholded z map',\n",
    "                         output_file=plot_path)\n",
    "    return secondlevel_mask, stat_maps_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af819413",
   "metadata": {},
   "source": [
    "### Create the second level GLM workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b15880eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate the first-level GLM workflow\n",
    "wf_secondlevel = Workflow(\n",
    "    name='wf_secondlevel',\n",
    "    input_spec=[\n",
    "        'n_subj',\n",
    "        'firstlevel_stats_list', \n",
    "        'firstlevel_contrast',\n",
    "        'n_perm',\n",
    "    ],\n",
    ")\n",
    "\n",
    "# add task - get_secondlevel_dm\n",
    "wf_secondlevel.add(\n",
    "    get_secondlevel_dm(\n",
    "        name = \"get_secondlevel_dm\",\n",
    "        n_subj = wf_secondlevel.lzin.n_subj, \n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - secondlevel_estimation\n",
    "wf_secondlevel.add(\n",
    "    secondlevel_estimation(\n",
    "        name = \"secondlevel_estimation\",\n",
    "        firstlevel_stats_list = wf_secondlevel.lzin.firstlevel_stats_list,  \n",
    "        design_matrix = wf_secondlevel.get_secondlevel_dm.lzout.design_matrix, \n",
    "        firstlevel_contrast = wf_secondlevel.lzin.firstlevel_contrast\n",
    "    )\n",
    ")\n",
    "\n",
    "# specify output\n",
    "wf_secondlevel.set_output(\n",
    "    [\n",
    "        ('second_level_designmatrix', wf_secondlevel.get_secondlevel_dm.lzout.design_matrix),\n",
    "        ('second_level_mask', wf_secondlevel.secondlevel_estimation.lzout.secondlevel_mask),\n",
    "        ('second_level_stats_map', wf_secondlevel.secondlevel_estimation.lzout.stat_maps_dict)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3178549",
   "metadata": {},
   "source": [
    "## Statistical Testing\n",
    "\n",
    "In this section, we present different ways of doing statistical testing\n",
    "\n",
    "1. Cluster-thresholding without multiple comparison\n",
    "2. Multiple comparison using FDR\n",
    "3. Paramatric testing\n",
    "4. Nonparamatric testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f228833",
   "metadata": {},
   "source": [
    "### Cluster-thresholding and Plot without multiple comparison\n",
    "\n",
    "Threshold the resulting map without multiple comparisons correction, abs(z) > 3.29 (equivalent to p < 0.001), cluster size > 10 voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db77b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': dict, 'threshold': float, 'cluster_threshold': int, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def cluster_thresholding(stat_maps_dict, threshold, cluster_threshold):\n",
    "    t1 = datetime.datetime.now()\n",
    "    print(\"\\nStart cluster thresholding ...\\n\")\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        thresholded_map = threshold_img(\n",
    "            img = stats_val['z_score'],\n",
    "            threshold=threshold,\n",
    "            cluster_threshold=cluster_threshold,\n",
    "            two_sided=True,\n",
    "        )\n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, 'secondlevel_cluster_thresholded_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        thresholded_map.to_filename(thresholded_map_path)\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_cluster_thresholded_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plot_stat_map(thresholded_map,\n",
    "                               title='Cluster Thresholded z map',\n",
    "                               output_file=plot_path)\n",
    "    print(\"\\nCluster thresholding is done\")\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a682d9bf",
   "metadata": {},
   "source": [
    "### Multiple comparison and Plot\n",
    "\n",
    "We have the following choices:\n",
    "- `fdr`: False Discovery Rate (FDR <.05) and no cluster-level threshold\n",
    "- `fpr`: False Positive Rate\n",
    "- `bonferroni`\n",
    "\n",
    "More details see [here](https://nilearn.github.io/stable/modules/generated/nilearn.glm.threshold_stats_img.html#nilearn.glm.threshold_stats_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a69a0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': dict, 'alpha': float, 'height_control': str, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def multiple_comparison(stat_maps_dict, alpha, height_control):\n",
    "    print(\"\\nStart multiple comparison ...\\n\")\n",
    "    from nilearn.glm import threshold_stats_img\n",
    "    from nilearn.plotting import plot_stat_map\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        thresholded_map, threshold = threshold_stats_img(\n",
    "            stat_img=stats_val['z_score'], \n",
    "            alpha=alpha, \n",
    "            height_control=height_control)\n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, \n",
    "                                         'secondlevel_multiple_comp_corrected_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        thresholded_map.to_filename(thresholded_map_path)\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_multiple_comp_corrected_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plot_stat_map(thresholded_map,\n",
    "                      title='Thresholded z map, expected fdr = .05',\n",
    "                      threshold=threshold, \n",
    "                      output_file=plot_path)\n",
    "    print(\"\\nMultiple comparison is done\")\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7c3cbf",
   "metadata": {},
   "source": [
    "### Paramatric test & Plot\n",
    "\n",
    "We threshold the second level contrast at uncorrected p < 0.001.\n",
    "\n",
    "A nilearn example see [here](https://nilearn.github.io/dev/auto_examples/05_glm_second_level/plot_second_level_one_sample_test.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26cf76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'stat_maps_dict': dict, \n",
    "     'secondlevel_mask': ty.Any,\n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def parametric_test(stat_maps_dict, secondlevel_mask):\n",
    "    print(\"\\nStart parametric test ...\\n\")\n",
    "    thresholded_map_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    plot_contrast_dict = dict.fromkeys(stat_maps_dict.keys())\n",
    "    for index, (stats_id, stats_val) in enumerate(stat_maps_dict.items()):\n",
    "        print('Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(stat_maps_dict), stats_id))\n",
    "        p_val = stats_val['p_value']\n",
    "        n_voxels = np.sum(get_data(img=secondlevel_mask))\n",
    "        # Correcting the p-values for multiple testing and taking negative logarithm\n",
    "        neg_log_pval = math_img(\"-np.log10(np.minimum(1, img * {}))\"\n",
    "                                .format(str(n_voxels)),\n",
    "                                img=p_val)\n",
    "        \n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, 'secondlevel_paramatric_thresholded_contrast-%s_z_map.nii.gz' % stats_id)\n",
    "        thresholded_map_dict[stats_id] = thresholded_map_path\n",
    "        neg_log_pval.to_filename(thresholded_map_path)\n",
    "    \n",
    "        # Since we are plotting negative log p-values and using a threshold equal to 1,\n",
    "        # it corresponds to corrected p-values lower than 10%, meaning that there is\n",
    "        # less than 10% probability to make a single false discovery (90% chance that\n",
    "        # we make no false discovery at all).  This threshold is much more conservative\n",
    "        # than the previous one.\n",
    "        title = ('parametric test (FWER < 10%)')\n",
    "        plot_path = os.path.join(workflow_out_dir, \n",
    "                                   'secondlevel_paramatric_thresholded_contrast-%s_zmap.jpg' % stats_id)\n",
    "        plot_contrast_dict[stats_id] = plot_path\n",
    "        plot_stat_map(\n",
    "            neg_log_pval, colorbar=True,\n",
    "            title=title, output_file=plot_path)\n",
    "    print(\"\\nParametric test is done\")\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1f7408",
   "metadata": {},
   "source": [
    "### Non-paramatric test & Plot\n",
    "\n",
    "Here we compute the (corrected) negative log p-values with permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1b06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pydra.mark.task\n",
    "@pydra.mark.annotate(\n",
    "    {'firstlevel_stats_list': list, 'smoothing_fwhm':float,'design_matrix': ty.Any, 'firstlevel_contrast': list, 'n_perm': int, \n",
    "     'return': {'thresholded_map_dict': dict, 'plot_contrast_dict': dict}}\n",
    ")\n",
    "def nonparametric_test(firstlevel_stats_list, smoothing_fwhm, design_matrix, firstlevel_contrast, n_perm):\n",
    "    print(f\"\\nStart nonparametric test ...\\n\")\n",
    "    thresholded_map_dict = dict.fromkeys(firstlevel_contrast[0][0].keys())\n",
    "    plot_contrast_dict = dict.fromkeys(firstlevel_contrast[0][0].keys())\n",
    "    for index, (contrast_id, contrast_val) in enumerate(firstlevel_contrast[0][0].items()):\n",
    "        print('  Contrast % 2i out of %i: %s' % (\n",
    "            index + 1, len(firstlevel_contrast[0][0]), contrast_id))\n",
    "        # here we set threshold as none to do voxel-level FWER-correction.\n",
    "        second_level_input = [nib.load(stats_dict[contrast_id]) for stats_dict in firstlevel_stats_list]\n",
    "        neg_log_pvals_permuted_ols_unmasked = \\\n",
    "            non_parametric_inference(second_level_input=second_level_input, design_matrix=design_matrix,\n",
    "                                     model_intercept=True, n_perm=n_perm,\n",
    "                                     two_sided_test=False, smoothing_fwhm=smoothing_fwhm, n_jobs=1)\n",
    "        thresholded_map_path = os.path.join(workflow_out_dir, 'secondlevel_permutation_contrast-%s_z_map.nii.gz' % contrast_id)\n",
    "        thresholded_map_dict[contrast_id] = thresholded_map_path\n",
    "        neg_log_pvals_permuted_ols_unmasked.to_filename(thresholded_map_path)\n",
    "        # here I actually have more than one contrast\n",
    "        title = ('permutation test (FWER < 10%)')\n",
    "        plot_path = os.path.join(workflow_out_dir, 'secondlevel_permutation_contrast-%s_zmap.jpg' % contrast_id)\n",
    "        plot_contrast_dict[contrast_id] = plot_path\n",
    "        plot_stat_map(\n",
    "            neg_log_pvals_permuted_ols_unmasked, colorbar=True, \n",
    "            title=title, output_file=plot_path)\n",
    "    print(\"\\nPermutation is done\")\n",
    "    return thresholded_map_dict, plot_contrast_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1b894",
   "metadata": {},
   "source": [
    "## The Ultimate Workflow\n",
    "\n",
    "Now, let's connect all tasks and workflows together.\n",
    "\n",
    "Here we randomly choose **5** subjects to perform the analysis. \n",
    "\n",
    "For computational time, we set `n_perm=100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9456c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = Workflow(\n",
    "    name='twolevel_glm',\n",
    "    input_spec=['n_subj'],\n",
    ")\n",
    "\n",
    "wf.inputs.n_subj = 2\n",
    "\n",
    "# randomly choose subjects\n",
    "wf_fixed_effect.inputs.subj_id = random.sample(range(1,17), wf.inputs.n_subj)\n",
    "wf_fixed_effect.inputs.run_id =[1,2]\n",
    "wf_fixed_effect.inputs.tr = 2.3\n",
    "wf_fixed_effect.inputs.n_scans = 300\n",
    "wf_fixed_effect.inputs.hrf_model = 'glover'\n",
    "wf_fixed_effect.inputs.smoothing_fwhm = 5.0\n",
    "wf.add(wf_fixed_effect)\n",
    "\n",
    "wf_secondlevel.inputs.n_subj = wf.inputs.n_subj\n",
    "wf_secondlevel.inputs.firstlevel_stats_list = wf.wf_fixed_effect.lzout.fx_t_test_list \n",
    "wf_secondlevel.inputs.firstlevel_contrast = wf.wf_fixed_effect.lzout.first_level_contrast\n",
    "wf.add(wf_secondlevel)\n",
    "\n",
    "# add task - cluster_thresholding\n",
    "wf.add(\n",
    "    cluster_thresholding(\n",
    "        name = \"cluster_thresholding\",\n",
    "        stat_maps_dict = wf.wf_secondlevel.lzout.second_level_stats_map, \n",
    "        threshold = 3.29, \n",
    "        cluster_threshold = 10\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# add task - multiple_comparison\n",
    "wf.add(\n",
    "    multiple_comparison(\n",
    "        name = \"multiple_comparison\",\n",
    "        stat_maps_dict = wf.wf_secondlevel.lzout.second_level_stats_map, \n",
    "        alpha = 0.05,\n",
    "        height_control = 'fdr'\n",
    "    )\n",
    ")\n",
    "\n",
    "# add task - parametric_test\n",
    "wf.add(\n",
    "    parametric_test(\n",
    "        name = \"parametric_test\",\n",
    "        stat_maps_dict =  wf.wf_secondlevel.lzout.second_level_stats_map, \n",
    "        secondlevel_mask = wf.wf_secondlevel.lzout.second_level_mask\n",
    "    )\n",
    "    \n",
    ")\n",
    "\n",
    "# add task - nonparametric_test\n",
    "wf.add(\n",
    "    nonparametric_test(\n",
    "        name = \"nonparametric_test\",\n",
    "        firstlevel_stats_list = wf.wf_fixed_effect.lzout.fx_t_test_list,\n",
    "        smoothing_fwhm = 5.0,\n",
    "        design_matrix = wf.wf_secondlevel.lzout.second_level_designmatrix,\n",
    "        firstlevel_contrast = wf.wf_fixed_effect.lzout.first_level_contrast,\n",
    "        n_perm = 100,\n",
    "    )\n",
    ")\n",
    "\n",
    "wf.set_output(\n",
    "    [\n",
    "        ('second_level_stats_map', wf.wf_secondlevel.lzout.second_level_stats_map)   \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed962858",
   "metadata": {},
   "source": [
    "### Run Workflow Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45315f25",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download data for subject-1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download data for subject-4"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get subject-1, run-1 firstlevel GLM design matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get subject-1, run-2 firstlevel GLM design matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-8' coro=<ConcurrentFuturesWorker.exec_as_coro() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py:173> exception=IndexError('list index out of range')>\n",
      "concurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/concurrent/futures/process.py\", line 254, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 529, in _run\n",
      "    self._run_task()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/task.py\", line 202, in _run_task\n",
      "    output = cp.loads(self.inputs._func)(**inputs)\n",
      "  File \"/tmp/ipykernel_2815/2321826732.py\", line 17, in get_firstlevel_dm\n",
      "    run_img = subj_imgs[run_id-1]\n",
      "              ~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 306, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py\", line 176, in exec_as_coro\n",
      "    res = await self.loop.run_in_executor(self.pool, runnable._run, rerun)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 286, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get subject-4, run-1 firstlevel GLM design matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-9' coro=<ConcurrentFuturesWorker.exec_as_coro() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py:173> exception=IndexError('list index out of range')>\n",
      "concurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/concurrent/futures/process.py\", line 254, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 529, in _run\n",
      "    self._run_task()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/task.py\", line 202, in _run_task\n",
      "    output = cp.loads(self.inputs._func)(**inputs)\n",
      "  File \"/tmp/ipykernel_2815/2321826732.py\", line 17, in get_firstlevel_dm\n",
      "    run_img = subj_imgs[run_id-1]\n",
      "              ~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 306, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py\", line 176, in exec_as_coro\n",
      "    res = await self.loop.run_in_executor(self.pool, runnable._run, rerun)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 286, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get subject-4, run-2 firstlevel GLM design matrix...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-7' coro=<load_and_run_async() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py:579> exception=ValueError(\"Tasks ['get_firstlevel_dm'] raised an error\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1365, in _collect_outputs\n",
      "    val_out = val.get_value(self)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1030, in get_value\n",
      "    value = get_nested_results(result, depth=split_depth)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1020, in get_nested_results\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Cannot retrieve value for contrasts from set_contrast as the node errored\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py\", line 585, in load_and_run_async\n",
      "    await task._run(submitter=submitter, rerun=rerun, **kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1237, in _run\n",
      "    result.output = self._collect_outputs()\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1371, in _collect_outputs\n",
      "    raise ValueError(\n",
      "        f\"Tasks {getattr(self, val.name)._errored} raised an error\"\n",
      "    )\n",
      "ValueError: Tasks ['get_firstlevel_dm'] raised an error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-6' coro=<load_and_run_async() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py:579> exception=ValueError(\"Tasks ['get_firstlevel_dm'] raised an error\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1365, in _collect_outputs\n",
      "    val_out = val.get_value(self)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1030, in get_value\n",
      "    value = get_nested_results(result, depth=split_depth)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1020, in get_nested_results\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Cannot retrieve value for contrasts from set_contrast as the node errored\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py\", line 585, in load_and_run_async\n",
      "    await task._run(submitter=submitter, rerun=rerun, **kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1237, in _run\n",
      "    result.output = self._collect_outputs()\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1371, in _collect_outputs\n",
      "    raise ValueError(\n",
      "        f\"Tasks {getattr(self, val.name)._errored} raised an error\"\n",
      "    )\n",
      "ValueError: Tasks ['get_firstlevel_dm'] raised an error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-12' coro=<ConcurrentFuturesWorker.exec_as_coro() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py:173> exception=IndexError('list index out of range')>\n",
      "concurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/concurrent/futures/process.py\", line 254, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 529, in _run\n",
      "    self._run_task()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/task.py\", line 202, in _run_task\n",
      "    output = cp.loads(self.inputs._func)(**inputs)\n",
      "  File \"/tmp/ipykernel_2815/2321826732.py\", line 17, in get_firstlevel_dm\n",
      "    run_img = subj_imgs[run_id-1]\n",
      "              ~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 306, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py\", line 176, in exec_as_coro\n",
      "    res = await self.loop.run_in_executor(self.pool, runnable._run, rerun)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 286, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-2' coro=<load_and_run_async() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py:579> exception=ValueError(\"Task wf_firstlevel raised an error, full crash report is here: [PosixPath('/tmp/tmp7a1mu_1l/Workflow_0eb6e0463a0ceca0072d995523b692ee/_error.pklz'), PosixPath('/tmp/tmp7a1mu_1l/Workflow_83f3b6ebcd3806f5c736a327e7dfa59f/_error.pklz')]\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1365, in _collect_outputs\n",
      "    val_out = val.get_value(self)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1030, in get_value\n",
      "    value = get_nested_results(result, depth=split_depth)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1015, in get_nested_results\n",
      "    val = StateArray[self.type](\n",
      "        get_nested_results(res=r, depth=depth - 1) for r in res\n",
      "    )\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1016, in <genexpr>\n",
      "    get_nested_results(res=r, depth=depth - 1) for r in res\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1020, in get_nested_results\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Cannot retrieve value for first_level_contrast from wf_firstlevel as the node errored\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py\", line 585, in load_and_run_async\n",
      "    await task._run(submitter=submitter, rerun=rerun, **kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1237, in _run\n",
      "    result.output = self._collect_outputs()\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1386, in _collect_outputs\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Task wf_firstlevel raised an error, full crash report is here: [PosixPath('/tmp/tmp7a1mu_1l/Workflow_0eb6e0463a0ceca0072d995523b692ee/_error.pklz'), PosixPath('/tmp/tmp7a1mu_1l/Workflow_83f3b6ebcd3806f5c736a327e7dfa59f/_error.pklz')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-13' coro=<ConcurrentFuturesWorker.exec_as_coro() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py:173> exception=IndexError('list index out of range')>\n",
      "concurrent.futures.process._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/concurrent/futures/process.py\", line 254, in _process_worker\n",
      "    r = call_item.fn(*call_item.args, **call_item.kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 529, in _run\n",
      "    self._run_task()\n",
      "    ~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/task.py\", line 202, in _run_task\n",
      "    output = cp.loads(self.inputs._func)(**inputs)\n",
      "  File \"/tmp/ipykernel_2815/2321826732.py\", line 17, in get_firstlevel_dm\n",
      "    run_img = subj_imgs[run_id-1]\n",
      "              ~~~~~~~~~^^^^^^^^^^\n",
      "IndexError: list index out of range\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 306, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/workers.py\", line 176, in exec_as_coro\n",
      "    res = await self.loop.run_in_executor(self.pool, runnable._run, rerun)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 286, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "    ~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py\", line 199, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-11' coro=<load_and_run_async() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py:579> exception=ValueError(\"Tasks ['get_firstlevel_dm'] raised an error\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1365, in _collect_outputs\n",
      "    val_out = val.get_value(self)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1030, in get_value\n",
      "    value = get_nested_results(result, depth=split_depth)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1020, in get_nested_results\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Cannot retrieve value for contrasts from set_contrast as the node errored\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py\", line 585, in load_and_run_async\n",
      "    await task._run(submitter=submitter, rerun=rerun, **kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1237, in _run\n",
      "    result.output = self._collect_outputs()\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1371, in _collect_outputs\n",
      "    raise ValueError(\n",
      "        f\"Tasks {getattr(self, val.name)._errored} raised an error\"\n",
      "    )\n",
      "ValueError: Tasks ['get_firstlevel_dm'] raised an error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-10' coro=<load_and_run_async() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py:579> exception=ValueError(\"Tasks ['get_firstlevel_dm'] raised an error\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1365, in _collect_outputs\n",
      "    val_out = val.get_value(self)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1030, in get_value\n",
      "    value = get_nested_results(result, depth=split_depth)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1020, in get_nested_results\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Cannot retrieve value for contrasts from set_contrast as the node errored\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py\", line 585, in load_and_run_async\n",
      "    await task._run(submitter=submitter, rerun=rerun, **kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1237, in _run\n",
      "    result.output = self._collect_outputs()\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1371, in _collect_outputs\n",
      "    raise ValueError(\n",
      "        f\"Tasks {getattr(self, val.name)._errored} raised an error\"\n",
      "    )\n",
      "ValueError: Tasks ['get_firstlevel_dm'] raised an error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-3' coro=<load_and_run_async() done, defined at /usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py:579> exception=ValueError(\"Task wf_firstlevel raised an error, full crash report is here: [PosixPath('/tmp/tmp7a1mu_1l/Workflow_520f5ffd532f544f2f8a063b589ffe05/_error.pklz'), PosixPath('/tmp/tmp7a1mu_1l/Workflow_1d94891ef83024fd873d1a94e35071cc/_error.pklz')]\")>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1365, in _collect_outputs\n",
      "    val_out = val.get_value(self)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1030, in get_value\n",
      "    value = get_nested_results(result, depth=split_depth)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1015, in get_nested_results\n",
      "    val = StateArray[self.type](\n",
      "        get_nested_results(res=r, depth=depth - 1) for r in res\n",
      "    )\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1016, in <genexpr>\n",
      "    get_nested_results(res=r, depth=depth - 1) for r in res\n",
      "    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py\", line 1020, in get_nested_results\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Cannot retrieve value for first_level_contrast from wf_firstlevel as the node errored\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/helpers.py\", line 585, in load_and_run_async\n",
      "    await task._run(submitter=submitter, rerun=rerun, **kwargs)\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1237, in _run\n",
      "    result.output = self._collect_outputs()\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py\", line 1386, in _collect_outputs\n",
      "    raise ValueError(\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "ValueError: Task wf_firstlevel raised an error, full crash report is here: [PosixPath('/tmp/tmp7a1mu_1l/Workflow_520f5ffd532f544f2f8a063b589ffe05/_error.pklz'), PosixPath('/tmp/tmp7a1mu_1l/Workflow_1d94891ef83024fd873d1a94e35071cc/_error.pklz')]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tasks ['wf_fixed_effect'] raised an error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py:1365\u001b[0m, in \u001b[0;36mWorkflow._collect_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1365\u001b[0m     val_out \u001b[38;5;241m=\u001b[39m \u001b[43mval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1366\u001b[0m     output_wf[name] \u001b[38;5;241m=\u001b[39m val_out\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py:1030\u001b[0m, in \u001b[0;36mLazyOutField.get_value\u001b[0;34m(self, wf, state_index)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n\u001b[0;32m-> 1030\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mget_nested_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_depth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_cast(value)\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/specs.py:1020\u001b[0m, in \u001b[0;36mLazyOutField.get_value.<locals>.get_nested_results\u001b[0;34m(res, depth)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39merrored:\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1021\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot retrieve value for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe node errored\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1023\u001b[0m     )\n\u001b[1;32m   1024\u001b[0m val \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mget_output_field(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfield)\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot retrieve value for second_level_stats_map from wf_secondlevel as the node errored",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydra\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Submitter\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Submitter(plugin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m, n_procs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m submitter:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43msubmitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m results \u001b[38;5;241m=\u001b[39m wf\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/submitter.py:42\u001b[0m, in \u001b[0;36mSubmitter.__call__\u001b[0;34m(self, runnable, cache_locations, rerun)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     runnable\u001b[38;5;241m.\u001b[39mcache_locations \u001b[38;5;241m=\u001b[39m cache_locations\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_from_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunnable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrerun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/futures.py:199\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/asyncio/tasks.py:304\u001b[0m, in \u001b[0;36mTask.__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/submitter.py:68\u001b[0m, in \u001b[0;36mSubmitter.submit_from_call\u001b[0;34m(self, runnable, rerun)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 1\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m runnable\u001b[38;5;241m.\u001b[39m_run(\u001b[38;5;28mself\u001b[39m, rerun\u001b[38;5;241m=\u001b[39mrerun)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# 3\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_runnable(runnable, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rerun\u001b[38;5;241m=\u001b[39mrerun)\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py:1237\u001b[0m, in \u001b[0;36mWorkflow._run\u001b[0;34m(self, submitter, rerun, **kwargs)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maudit\u001b[38;5;241m.\u001b[39mmonitor()\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_task(submitter, rerun\u001b[38;5;241m=\u001b[39mrerun)\n\u001b[0;32m-> 1237\u001b[0m     result\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m     etype, \u001b[38;5;28meval\u001b[39m, etr \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/pydra-tutorial/lib/python3.13/site-packages/pydra/engine/core.py:1371\u001b[0m, in \u001b[0;36mWorkflow._collect_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;66;03m# checking if the tasks has predecessors that raises error\u001b[39;00m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, val\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_errored, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1372\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTasks \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m,\u001b[38;5;250m \u001b[39mval\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39m_errored\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m raised an error\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m     )\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, val\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;28mlist\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: Tasks ['wf_fixed_effect'] raised an error"
     ]
    }
   ],
   "source": [
    "from pydra import Submitter\n",
    "\n",
    "with Submitter(plugin='cf', n_procs=1) as submitter:\n",
    "    submitter(wf)\n",
    "\n",
    "results = wf.result()\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23dfc57",
   "metadata": {},
   "source": [
    "## Let's Plot!\n",
    "\n",
    "We only use 5 subjects, so it's reasonable the following plots have nothing survived from testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc6a6b6",
   "metadata": {},
   "source": [
    "### Unthresholded\n",
    "\n",
    "Let's plot the unthresholded image first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8059e10",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      2\u001b[0m ut_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workflow_out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondlevel_unthresholded*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[43mut_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "ut_list = glob.glob(os.path.join(workflow_out_dir, \"secondlevel_unthresholded*.jpg\"))\n",
    "Image(filename=ut_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c945fb",
   "metadata": {},
   "source": [
    "### Cluster Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e5dc8fe",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      2\u001b[0m ct_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workflow_out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondlevel_cluster_thresholded*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[43mct_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "ct_list = glob.glob(os.path.join(workflow_out_dir, \"secondlevel_cluster_thresholded*.jpg\"))\n",
    "Image(filename=ct_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c80a74",
   "metadata": {},
   "source": [
    "### Multiple Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc2123c3",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m mc_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workflow_out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondlevel_multiple_comp*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[43mmc_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "mc_list = glob.glob(os.path.join(workflow_out_dir, \"secondlevel_multiple_comp*.jpg\"))\n",
    "Image(filename=mc_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63d9178",
   "metadata": {},
   "source": [
    "### Paramatric Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d10da5f1",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pt_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workflow_out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondlevel_paramatric*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[43mpt_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pt_list = glob.glob(os.path.join(workflow_out_dir, \"secondlevel_paramatric*.jpg\"))\n",
    "Image(filename=pt_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31809bd8",
   "metadata": {},
   "source": [
    "### Nonparamatric Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d349f994",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m npt_list \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(workflow_out_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondlevel_permutation*.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 2\u001b[0m Image(filename\u001b[38;5;241m=\u001b[39m\u001b[43mnpt_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "npt_list = glob.glob(os.path.join(workflow_out_dir, \"secondlevel_permutation*.jpg\"))\n",
    "Image(filename=npt_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddb01d",
   "metadata": {},
   "source": [
    "## Exercise #1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968e470",
   "metadata": {},
   "source": [
    "In this example, we conducted GLM on each run per subject separately and then used a fixed-effect model to average across runs. \n",
    "\n",
    "Where did we put `.splitter` and `.combiner`. Why did we put it there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350467d",
   "metadata": {},
   "source": [
    "## Exercise #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8316f",
   "metadata": {},
   "source": [
    "Moreover, We choose this approach due to limited memory on GitHub. [FirstLevelModel](https://nilearn.github.io/stable/modules/generated/nilearn.glm.first_level.FirstLevelModel.html) in Nilearn also allows to compute multiple runs with a fixed-effect model simultanously. Here is an [example](https://nilearn.github.io/stable/auto_examples/04_glm_first_level/plot_fiac_analysis.html#sphx-glr-auto-examples-04-glm-first-level-plot-fiac-analysis-py). \n",
    "\n",
    "Would you like to give it a try on your own?"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.15.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "source_map": [
   13,
   17,
   26,
   29,
   35,
   63,
   73,
   86,
   98,
   110,
   141,
   149,
   155,
   192,
   196,
   220,
   224,
   269,
   275,
   341,
   347,
   385,
   389,
   445,
   454,
   462,
   472,
   478,
   507,
   511,
   549,
   560,
   566,
   597,
   608,
   640,
   648,
   687,
   693,
   724,
   734,
   804,
   808,
   819,
   825,
   831,
   837,
   841,
   847,
   851,
   856,
   860,
   865,
   869,
   874,
   878,
   884,
   888
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}